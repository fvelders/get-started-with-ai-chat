# Configuratie voor zelf-gehoste modellen op NAS
# Kopieer dit bestand naar .env en vul de waarden in

# ======================================
# MODEL PROVIDER CONFIGURATIE
# ======================================

# Kies je model provider:
# - "azure" = Azure OpenAI (vereist Azure credentials)
# - "local" of "openai-compatible" = Zelf-gehoste model (Ollama, LocalAI, LM Studio, vLLM, etc.)
MODEL_PROVIDER="local"

# ======================================
# LOKAAL MODEL CONFIGURATIE
# ======================================

# Base URL van je model API (OpenAI-compatible endpoint)
# Voorbeelden:
#   Ollama:     http://localhost:11434
#   LocalAI:    http://localhost:8080
#   LM Studio:  http://localhost:1234
#   vLLM:       http://localhost:8000
#   text-generation-webui: http://localhost:5000
MODEL_BASE_URL="http://localhost:11434"

# Model naam die je wilt gebruiken
# Voor Ollama: llama3.2, mistral, phi3, etc.
# Voor LocalAI: naam zoals geconfigureerd in je models directory
# Voor LM Studio: de model naam uit de UI
MODEL_NAME="llama3.2"

# API key (optioneel, meestal "not-needed" voor lokale modellen)
# Sommige setups vereisen wel een key voor authenticatie
MODEL_API_KEY="not-needed"

# ======================================
# CORS CONFIGURATIE
# ======================================

# Frontend origins die toegang mogen hebben (verplicht voor gescheiden frontend/backend)
# Meerdere origins scheiden met komma's
CORS_ORIGINS="http://localhost:5173,http://localhost:3000,http://192.168.1.100:5173"

# ======================================
# OPTIONELE CONFIGURATIE
# ======================================

# Basic authenticatie (optioneel - voor extra beveiliging)
WEB_APP_USERNAME=""
WEB_APP_PASSWORD=""

# Logging
APP_LOG_FILE=""

# Production mode
RUNNING_IN_PRODUCTION="false"

# ======================================
# AZURE (NIET VEREIST VOOR LOKAAL MODEL)
# ======================================

# Deze kunnen leeg blijven als je alleen lokale modellen gebruikt
# Ze zijn alleen nodig als MODEL_PROVIDER="azure"

# AZURE_AIPROJECT_CONNECTION_STRING=""
# AZURE_AI_CHAT_DEPLOYMENT_NAME=""
# AZURE_EXISTING_AIPROJECT_ENDPOINT=""

# RAG/Search (momenteel alleen ondersteund met Azure)
# AZURE_AI_EMBED_DEPLOYMENT_NAME=""
# AZURE_AI_EMBED_DIMENSIONS=""
# AZURE_AI_SEARCH_ENDPOINT=""
# AZURE_AI_SEARCH_INDEX_NAME=""
